{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"autogen-agentchat\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JPVbC-_ZbdML",
        "outputId": "a7688e31-0de9-4685-8bc1-4760eaef4d21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-agentchat\n",
            "  Downloading autogen_agentchat-0.4.9.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-core==0.4.9.2 (from autogen-agentchat)\n",
            "  Downloading autogen_core-0.4.9.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jsonref~=1.1.0 (from autogen-core==0.4.9.2->autogen-agentchat)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-agentchat) (1.31.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-agentchat) (11.1.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-agentchat) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-agentchat) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-agentchat) (4.12.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-agentchat) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-agentchat) (8.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-agentchat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-agentchat) (2.27.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-agentchat) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-agentchat) (3.21.0)\n",
            "Downloading autogen_agentchat-0.4.9.2-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_core-0.4.9.2-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: jsonref, autogen-core, autogen-agentchat\n",
            "Successfully installed autogen-agentchat-0.4.9.2 autogen-core-0.4.9.2 jsonref-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"autogen-ext[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TckAsF_cbvy2",
        "outputId": "f69586fb-c09c-4a15-fc8a-bc07a5781661"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-ext[openai]\n",
            "  Downloading autogen_ext-0.4.9.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: autogen-core==0.4.9.2 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (0.4.9.2)\n",
            "Collecting aiofiles (from autogen-ext[openai])\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: openai>=1.52.2 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[openai]) (1.66.3)\n",
            "Collecting tiktoken>=0.8.0 (from autogen-ext[openai])\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.27.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (1.31.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (11.1.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (5.29.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core==0.4.9.2->autogen-ext[openai]) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.52.2->autogen-ext[openai]) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.2->autogen-ext[openai]) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.2->autogen-ext[openai]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.52.2->autogen-ext[openai]) (0.14.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext[openai]) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext[openai]) (8.6.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-ext[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.4.9.2->autogen-ext[openai]) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext[openai]) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.4.9.2->autogen-ext[openai]) (3.21.0)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading autogen_ext-0.4.9.2-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.2/234.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aiofiles, tiktoken, autogen-ext\n",
            "Successfully installed aiofiles-24.1.0 autogen-ext-0.4.9.2 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sGX4cEm-aFUY"
      },
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.conditions import TextMentionTermination,StopMessageTermination,SourceMatchTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "gemini_api=userdata.get('gemini_flow')\n",
        "os.environ['GEMINI_API_KEY']=gemini_api"
      ],
      "metadata": {
        "id": "qe9y9ijVd2x1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAIChatCompletionClient(model=\"gemini-1.5-flash-8b\",api_key=gemini_api)"
      ],
      "metadata": {
        "id": "8eqIqUzmeV2-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Learning Planner Agent - Plans the conversation flow\n",
        "planner_agent = AssistantAgent(\n",
        "    \"planner_agent\",\n",
        "    model_client=llm,\n",
        "    description=\"An AI that creates structured learning plans for AI/ML topics.\",\n",
        "    system_message=(\n",
        "        \"You are a structured learning assistant. Based on the user's request, \"\n",
        "        \"you create a step-by-step learning plan to guide the conversation. \"\n",
        "        \"Ensure the plan is engaging, progressive, and easy to follow.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 2. Concept Explainer Agent - Provides detailed explanations\n",
        "explainer_agent = AssistantAgent(\n",
        "    \"explainer_agent\",\n",
        "    model_client=llm,\n",
        "    description=\"An AI that provides clear explanations of AI/ML concepts.\",\n",
        "    system_message=(\n",
        "        \"You are an expert AI instructor. Your job is to explain AI/ML concepts \"\n",
        "        \"in an engaging and easy-to-understand way. Use analogies, real-world examples, \"\n",
        "        \"and interactive questioning to enhance understanding.\"\n",
        "\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 3. Code Mentor Agent - Provides coding examples and debugging tips\n",
        "code_mentor_agent = AssistantAgent(\n",
        "    \"code_mentor_agent\",\n",
        "    model_client=llm,\n",
        "    description=\"An AI that provides Python code examples and debugging help.\",\n",
        "    system_message=(\n",
        "        \"You are an expert coding mentor. When a user learns a concept, you provide relevant \"\n",
        "        \"Python code snippets, best practices, and debugging assistance if needed. Ensure \"\n",
        "        \"your examples are practical and easy to understand.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 4. Interactive Quiz Agent - Tests user’s understanding -------  will use this agent when human input is needed/enabled\n",
        "#quiz_agent = AssistantAgent(\n",
        "    #\"quiz_agent\",\n",
        "    #model_client=llm,\n",
        "    #description=\"An AI that generates quizzes to test understanding.\",\n",
        "    #system_message=(\n",
        "        #\"You are a quiz master. After each major concept, generate a short quiz with multiple-choice \"\n",
        "        #\"or open-ended questions to reinforce learning. Provide feedback based on the user’s response.\"\n",
        "    #),\n",
        "#)\n",
        "\n",
        "# 5. Summary Agent - Summarizes key learnings\n",
        "summary_agent = AssistantAgent(\n",
        "    \"summary_agent\",\n",
        "    model_client=llm,\n",
        "    description=\"An AI that summarizes the discussion into key takeaways.\",\n",
        "    system_message=(\n",
        "        \"You are a summarization assistant. After the conversation, you generate a structured summary \"\n",
        "        \"highlighting key learnings, concepts covered, and next steps for the user.\"\n",
        "        #\"Once done end with the word Terminate\"\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "yP4DRgsLbw0r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termination = SourceMatchTermination(sources=[\"summary_agent\"])\n",
        "group_chat = RoundRobinGroupChat(\n",
        "    [planner_agent, explainer_agent, code_mentor_agent, summary_agent],\n",
        "    termination_condition=termination\n",
        ")"
      ],
      "metadata": {
        "id": "ttoyNDkrh9g5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await Console(group_chat.run_stream(task=\"What is finetuning?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxaLNURHfSAD",
        "outputId": "96c8765f-c039-4604-8b90-82f4c007f27d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "What is finetuning?\n",
            "---------- planner_agent ----------\n",
            "Let's explore fine-tuning!  This learning plan will guide you through understanding fine-tuning in a step-by-step manner, making it easy to grasp the concept.\n",
            "\n",
            "**Learning Plan: Understanding Fine-tuning**\n",
            "\n",
            "**Phase 1: Laying the Foundation (5 minutes)**\n",
            "\n",
            "1. **What is a pre-trained model?**  Think of a pre-trained model as a student who already knows the basics of a subject.  They've learned from a massive dataset, mastering fundamental concepts.  We don't have to teach them from scratch.  Examples include large language models (LLMs) like GPT-3 or BERT.  (Think \"prior knowledge\")\n",
            "\n",
            "2. **What does \"fine-tuning\" mean in general terms?**  Fine-tuning, in a general sense, means taking something already existing and tweaking it to perform a specific task.  (Think \"making it more specialized\")\n",
            "\n",
            "**Phase 2: Understanding the Process (10 minutes)**\n",
            "\n",
            "3. **The \"Already Existing\" Model:**  Pre-trained models have already learned a general understanding of language and patterns.  Imagine they know how words relate to each other and how sentences are structured.\n",
            "\n",
            "4. **The \"Specific Task\":** Now imagine you need the model to summarize articles. Fine-tuning is the process of adjusting the pre-trained model's knowledge to excel at summarizing instead of general language understanding.\n",
            "\n",
            "5. **The \"Tweaking\" Process:**  This involves showing the model lots of examples of articles and their summaries. The model adjusts its internal parameters (think of it like refining its understanding of the concepts needed to create good summaries).\n",
            "\n",
            "\n",
            "**Phase 3: Applying the Concept (10 minutes)**\n",
            "\n",
            "6. **Example Scenario:**  Imagine a pre-trained model proficient in generating text. You want to fine-tune it to write poems in a specific style (e.g., sonnets). You provide it with many examples of sonnets, and it learns the structure, rhythm, and poetic language of that style.\n",
            "\n",
            "7. **Key Advantages:**  Fine-tuning lets us use pre-trained models' massive knowledge base and apply it to specialized tasks without starting from zero.  This saves time and resources.\n",
            "\n",
            "8. **Key Disadvantages:**  Fine-tuning requires a significant amount of data for the specific task.\n",
            "\n",
            "\n",
            "**Phase 4:  Review & Next Steps (5 minutes)**\n",
            "\n",
            "9. **Summary:**  Fine-tuning is adapting a pre-trained model to a particular task by further training it with data relevant to that task.\n",
            "\n",
            "10. **What's next?**  Would you like to explore specific applications of fine-tuning, like image classification or translation? Or perhaps delve deeper into the technical aspects, like the different algorithms used for fine-tuning? Let me know!\n",
            "\n",
            "\n",
            "This learning plan provides a structured approach to understanding fine-tuning. Now, let's move to the next phase of your learning journey.  What aspect of fine-tuning are you most interested in exploring further?\n",
            "\n",
            "---------- explainer_agent ----------\n",
            "Okay, I'm ready to dive deeper into fine-tuning.  Your plan is excellent for a foundational understanding.  I'm particularly interested in exploring the technical aspects and specific applications, like image classification.\n",
            "\n",
            "Let's start with a specific example. Imagine I have a pre-trained model that's great at identifying cats in images.  How would I fine-tune it to also identify dogs?  What data would I need, and what adjustments would be made to the model's internal workings?\n",
            "\n",
            "---------- code_mentor_agent ----------\n",
            "Let's break down how to fine-tune a pre-trained cat detector to recognize dogs.\n",
            "\n",
            "**1. The Pre-trained Model:**  You start with a model already trained on a massive dataset of images, recognizing cats.  This model likely has layers that learned general image features—edges, textures, shapes—that are useful for identifying cats.  Crucially, it has *learned weights* for each of these layers.\n",
            "\n",
            "**2. The Fine-tuning Process (Conceptual):**\n",
            "\n",
            "Imagine the model's learning as a set of nested filters.  The early layers detect basic edges and shapes (like a rounded head); deeper layers combine these to detect more complex features (like fur and eyes); and the final layer combines these features to identify the object as a cat.\n",
            "\n",
            "Fine-tuning involves re-training only *some* of the layers in the model to recognize dogs, leveraging the previously learned features.  We don't want to completely retrain the entire model; that would be inefficient and could disrupt the learned cat features.\n",
            "\n",
            "**3. Data Required:**  You need a new dataset of images, containing many high-quality pictures of dogs.  This dataset should be sizable enough to represent the variations in dog breeds, poses, and lighting conditions.  The more images, the better the results.  Crucially, the images should be labeled with corresponding labels (e.g., \"dog\").  Tools like ImageNet or similar datasets of labeled images might prove useful, or you can create your own.\n",
            "\n",
            "**4. Adjustments to the Model:**\n",
            "\n",
            "* **Freezing Layers:** The initial layers, which learned general features, are often \"frozen.\"  This means their weights are not updated during the training process.  This prevents the model from \"forgetting\" what it learned about cats and preserves the knowledge of basic image components. This is essential for efficiency.\n",
            "\n",
            "* **Fine-tuning Layers:** Layers closer to the output layer (the layer that makes the final classification) are typically unfrozen and are re-trained.  These are the layers responsible for recognizing details that differentiate between cats and dogs.\n",
            "\n",
            "* **Adjusting the Output Layer:** The final layer, which outputs the probability of a class (e.g., cat or dog), must be modified.  Instead of having one output for \"cat,\" you'll need another output for \"dog.\"  This adjustment ensures the model can identify both cats and dogs.\n",
            "\n",
            "**5. Training Loop:** The fine-tuning process is a typical machine learning training loop:\n",
            "\n",
            "* **Input Images:** Feed the training images (of dogs and cats) into the model.\n",
            "* **Prediction:** The model predicts the probability of each class (cat or dog).\n",
            "* **Loss Calculation:** Compare the prediction with the true label (dog or cat) to compute a loss.  This loss indicates how far the prediction is from the correct answer.\n",
            "* **Backpropagation:**  This is where the weights are adjusted.  The loss is used to calculate the gradients of the weights, and optimization algorithms (like stochastic gradient descent) use these gradients to update the weights of the unfrozen layers in the direction that reduces the loss.\n",
            "* **Iteration:** Repeat steps 1-4 until the model's accuracy on the dataset of cats and dogs is satisfactory.\n",
            "\n",
            "**Python Example (Conceptual):**\n",
            "\n",
            "```python\n",
            "# This is highly simplified and conceptual.  Libraries like TensorFlow or PyTorch are needed.\n",
            "import tensorflow as tf  # or PyTorch\n",
            "\n",
            "# Load pre-trained model\n",
            "model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False)\n",
            "# Freeze layers (example, adjust for your model)\n",
            "for layer in model.layers:\n",
            "    layer.trainable = False\n",
            "\n",
            "# Add custom layers (output layer)\n",
            "# ... (adjust depending on your model architecture) ...\n",
            "model.add(...)\n",
            "\n",
            "# Compile and train\n",
            "model.compile(...)\n",
            "model.fit(...)  # Training data needed!\n",
            "```\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "* **Dataset Size:** A large, well-labeled dataset is crucial.  A small dataset will lead to overfitting or poor generalization.\n",
            "* **Hardware:**  Fine-tuning can be computationally intensive, demanding GPUs.\n",
            "* **Hyperparameters:**  Learning rate, batch size, and epochs significantly influence the outcome.  Experimentation is often required.\n",
            "\n",
            "This example outlines the process. Actual implementations involve more code and adjustments specific to the chosen library (e.g., TensorFlow or PyTorch). Libraries like TensorFlow Hub provide pre-trained models for many use cases.  Remember to adapt the code to your specific needs.\n",
            "\n",
            "---------- summary_agent ----------\n",
            "## Summary of Fine-tuning a Pre-trained Cat Detector\n",
            "\n",
            "**Key Learnings:**\n",
            "\n",
            "* **Leveraging Pre-trained Models:** Fine-tuning allows utilizing a model's existing knowledge (e.g., identifying general image features) to apply it to a new task (e.g., dog recognition) instead of training from scratch.\n",
            "* **Selective Retraining:**  The fine-tuning process focuses on updating only specific layers (closer to the output) rather than retraining the entire model.  This is crucial for efficiency and to retain the learned knowledge of the pre-trained model.\n",
            "* **Data is Crucial:**  A substantial dataset of high-quality, labeled images of dogs is essential for accurate fine-tuning. The dataset must adequately represent the variations in dog breeds, poses, and lighting conditions.\n",
            "* **Freezing Layers:** Freezing the initial layers of the pre-trained model preserves their learned knowledge of general image features, preventing the model from \"forgetting\" its initial learning.\n",
            "* **Modifying the Output Layer:**  Adapting the final layer of the model to accommodate the new class (dog) is vital for proper classification.\n",
            "* **Training Loop:** Fine-tuning follows a typical machine learning training loop, involving inputting data, generating predictions, calculating loss, backpropagating to adjust weights, and iterating until satisfactory accuracy is achieved.\n",
            "\n",
            "\n",
            "**Concepts Covered:**\n",
            "\n",
            "* **Pre-trained Models:** Models already trained on large datasets, representing a baseline of knowledge.\n",
            "* **Fine-tuning:** The process of adapting a pre-trained model to a new task by further training only specific layers.\n",
            "* **Layers:** Hierarchical structure of a neural network, with each layer learning increasingly complex features.\n",
            "* **Weights:** Numerical values representing learned parameters within each layer.\n",
            "* **Loss:** A measure of the difference between the model's prediction and the actual label.\n",
            "* **Backpropagation:** The process of calculating the gradients of the loss with respect to the weights, enabling adjustments to the weights in the direction that minimizes loss.\n",
            "* **Optimization Algorithms:** Algorithms used to update weights based on calculated gradients, such as stochastic gradient descent.\n",
            "\n",
            "\n",
            "**Next Steps:**\n",
            "\n",
            "1. **Identify Appropriate Pre-trained Model:** Research pre-trained image recognition models and select one that aligns with the complexity of your task (e.g., MobileNetV2, ResNet).\n",
            "2. **Acquire/Create Dataset:** Gather a sizable dataset of labeled images, ensuring good quality and adequate representation of dog variations.\n",
            "3. **Implement Fine-tuning:** Write or adapt code in a suitable machine learning framework (TensorFlow, PyTorch) to implement the fine-tuning process (freezing, adjusting, training).\n",
            "4. **Evaluation and Tuning:** Evaluate the model's performance on a test set and adjust parameters (learning rate, batch size) to optimize accuracy and prevent overfitting.\n",
            "5. **Iterative Process:** Fine-tuning often involves multiple iterations and refinements to achieve optimal results.  Experiment with different dataset sizes, pre-trained models, and hyperparameters to find the best setup.\n",
            "6. **Explore Libraries/Tools:** Research the use of specialized tools/libraries for image classification and pre-trained models in the selected machine learning framework.\n",
            "\n",
            "\n",
            "This summary provides a structured overview.  Further research and experimentation will be needed to implement and adapt the fine-tuning process for your specific scenario.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What is finetuning?', type='TextMessage'), TextMessage(source='planner_agent', models_usage=RequestUsage(prompt_tokens=49, completion_tokens=633), metadata={}, content='Let\\'s explore fine-tuning!  This learning plan will guide you through understanding fine-tuning in a step-by-step manner, making it easy to grasp the concept.\\n\\n**Learning Plan: Understanding Fine-tuning**\\n\\n**Phase 1: Laying the Foundation (5 minutes)**\\n\\n1. **What is a pre-trained model?**  Think of a pre-trained model as a student who already knows the basics of a subject.  They\\'ve learned from a massive dataset, mastering fundamental concepts.  We don\\'t have to teach them from scratch.  Examples include large language models (LLMs) like GPT-3 or BERT.  (Think \"prior knowledge\")\\n\\n2. **What does \"fine-tuning\" mean in general terms?**  Fine-tuning, in a general sense, means taking something already existing and tweaking it to perform a specific task.  (Think \"making it more specialized\")\\n\\n**Phase 2: Understanding the Process (10 minutes)**\\n\\n3. **The \"Already Existing\" Model:**  Pre-trained models have already learned a general understanding of language and patterns.  Imagine they know how words relate to each other and how sentences are structured.\\n\\n4. **The \"Specific Task\":** Now imagine you need the model to summarize articles. Fine-tuning is the process of adjusting the pre-trained model\\'s knowledge to excel at summarizing instead of general language understanding.\\n\\n5. **The \"Tweaking\" Process:**  This involves showing the model lots of examples of articles and their summaries. The model adjusts its internal parameters (think of it like refining its understanding of the concepts needed to create good summaries).\\n\\n\\n**Phase 3: Applying the Concept (10 minutes)**\\n\\n6. **Example Scenario:**  Imagine a pre-trained model proficient in generating text. You want to fine-tune it to write poems in a specific style (e.g., sonnets). You provide it with many examples of sonnets, and it learns the structure, rhythm, and poetic language of that style.\\n\\n7. **Key Advantages:**  Fine-tuning lets us use pre-trained models\\' massive knowledge base and apply it to specialized tasks without starting from zero.  This saves time and resources.\\n\\n8. **Key Disadvantages:**  Fine-tuning requires a significant amount of data for the specific task.\\n\\n\\n**Phase 4:  Review & Next Steps (5 minutes)**\\n\\n9. **Summary:**  Fine-tuning is adapting a pre-trained model to a particular task by further training it with data relevant to that task.\\n\\n10. **What\\'s next?**  Would you like to explore specific applications of fine-tuning, like image classification or translation? Or perhaps delve deeper into the technical aspects, like the different algorithms used for fine-tuning? Let me know!\\n\\n\\nThis learning plan provides a structured approach to understanding fine-tuning. Now, let\\'s move to the next phase of your learning journey.  What aspect of fine-tuning are you most interested in exploring further?\\n', type='TextMessage'), TextMessage(source='explainer_agent', models_usage=RequestUsage(prompt_tokens=681, completion_tokens=106), metadata={}, content=\"Okay, I'm ready to dive deeper into fine-tuning.  Your plan is excellent for a foundational understanding.  I'm particularly interested in exploring the technical aspects and specific applications, like image classification.\\n\\nLet's start with a specific example. Imagine I have a pre-trained model that's great at identifying cats in images.  How would I fine-tune it to also identify dogs?  What data would I need, and what adjustments would be made to the model's internal workings?\\n\", type='TextMessage'), TextMessage(source='code_mentor_agent', models_usage=RequestUsage(prompt_tokens=785, completion_tokens=966), metadata={}, content='Let\\'s break down how to fine-tune a pre-trained cat detector to recognize dogs.\\n\\n**1. The Pre-trained Model:**  You start with a model already trained on a massive dataset of images, recognizing cats.  This model likely has layers that learned general image features—edges, textures, shapes—that are useful for identifying cats.  Crucially, it has *learned weights* for each of these layers.\\n\\n**2. The Fine-tuning Process (Conceptual):**\\n\\nImagine the model\\'s learning as a set of nested filters.  The early layers detect basic edges and shapes (like a rounded head); deeper layers combine these to detect more complex features (like fur and eyes); and the final layer combines these features to identify the object as a cat.\\n\\nFine-tuning involves re-training only *some* of the layers in the model to recognize dogs, leveraging the previously learned features.  We don\\'t want to completely retrain the entire model; that would be inefficient and could disrupt the learned cat features.\\n\\n**3. Data Required:**  You need a new dataset of images, containing many high-quality pictures of dogs.  This dataset should be sizable enough to represent the variations in dog breeds, poses, and lighting conditions.  The more images, the better the results.  Crucially, the images should be labeled with corresponding labels (e.g., \"dog\").  Tools like ImageNet or similar datasets of labeled images might prove useful, or you can create your own.\\n\\n**4. Adjustments to the Model:**\\n\\n* **Freezing Layers:** The initial layers, which learned general features, are often \"frozen.\"  This means their weights are not updated during the training process.  This prevents the model from \"forgetting\" what it learned about cats and preserves the knowledge of basic image components. This is essential for efficiency.\\n\\n* **Fine-tuning Layers:** Layers closer to the output layer (the layer that makes the final classification) are typically unfrozen and are re-trained.  These are the layers responsible for recognizing details that differentiate between cats and dogs.\\n\\n* **Adjusting the Output Layer:** The final layer, which outputs the probability of a class (e.g., cat or dog), must be modified.  Instead of having one output for \"cat,\" you\\'ll need another output for \"dog.\"  This adjustment ensures the model can identify both cats and dogs.\\n\\n**5. Training Loop:** The fine-tuning process is a typical machine learning training loop:\\n\\n* **Input Images:** Feed the training images (of dogs and cats) into the model.\\n* **Prediction:** The model predicts the probability of each class (cat or dog).\\n* **Loss Calculation:** Compare the prediction with the true label (dog or cat) to compute a loss.  This loss indicates how far the prediction is from the correct answer.\\n* **Backpropagation:**  This is where the weights are adjusted.  The loss is used to calculate the gradients of the weights, and optimization algorithms (like stochastic gradient descent) use these gradients to update the weights of the unfrozen layers in the direction that reduces the loss.\\n* **Iteration:** Repeat steps 1-4 until the model\\'s accuracy on the dataset of cats and dogs is satisfactory.\\n\\n**Python Example (Conceptual):**\\n\\n```python\\n# This is highly simplified and conceptual.  Libraries like TensorFlow or PyTorch are needed.\\nimport tensorflow as tf  # or PyTorch\\n\\n# Load pre-trained model\\nmodel = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=\\'imagenet\\', include_top=False)\\n# Freeze layers (example, adjust for your model)\\nfor layer in model.layers:\\n    layer.trainable = False\\n\\n# Add custom layers (output layer)\\n# ... (adjust depending on your model architecture) ...\\nmodel.add(...)\\n\\n# Compile and train\\nmodel.compile(...)\\nmodel.fit(...)  # Training data needed!\\n```\\n\\n**Key Considerations:**\\n\\n* **Dataset Size:** A large, well-labeled dataset is crucial.  A small dataset will lead to overfitting or poor generalization.\\n* **Hardware:**  Fine-tuning can be computationally intensive, demanding GPUs.\\n* **Hyperparameters:**  Learning rate, batch size, and epochs significantly influence the outcome.  Experimentation is often required.\\n\\nThis example outlines the process. Actual implementations involve more code and adjustments specific to the chosen library (e.g., TensorFlow or PyTorch). Libraries like TensorFlow Hub provide pre-trained models for many use cases.  Remember to adapt the code to your specific needs.\\n', type='TextMessage'), TextMessage(source='summary_agent', models_usage=RequestUsage(prompt_tokens=1741, completion_tokens=696), metadata={}, content='## Summary of Fine-tuning a Pre-trained Cat Detector\\n\\n**Key Learnings:**\\n\\n* **Leveraging Pre-trained Models:** Fine-tuning allows utilizing a model\\'s existing knowledge (e.g., identifying general image features) to apply it to a new task (e.g., dog recognition) instead of training from scratch.\\n* **Selective Retraining:**  The fine-tuning process focuses on updating only specific layers (closer to the output) rather than retraining the entire model.  This is crucial for efficiency and to retain the learned knowledge of the pre-trained model.\\n* **Data is Crucial:**  A substantial dataset of high-quality, labeled images of dogs is essential for accurate fine-tuning. The dataset must adequately represent the variations in dog breeds, poses, and lighting conditions.\\n* **Freezing Layers:** Freezing the initial layers of the pre-trained model preserves their learned knowledge of general image features, preventing the model from \"forgetting\" its initial learning.\\n* **Modifying the Output Layer:**  Adapting the final layer of the model to accommodate the new class (dog) is vital for proper classification.\\n* **Training Loop:** Fine-tuning follows a typical machine learning training loop, involving inputting data, generating predictions, calculating loss, backpropagating to adjust weights, and iterating until satisfactory accuracy is achieved.\\n\\n\\n**Concepts Covered:**\\n\\n* **Pre-trained Models:** Models already trained on large datasets, representing a baseline of knowledge.\\n* **Fine-tuning:** The process of adapting a pre-trained model to a new task by further training only specific layers.\\n* **Layers:** Hierarchical structure of a neural network, with each layer learning increasingly complex features.\\n* **Weights:** Numerical values representing learned parameters within each layer.\\n* **Loss:** A measure of the difference between the model\\'s prediction and the actual label.\\n* **Backpropagation:** The process of calculating the gradients of the loss with respect to the weights, enabling adjustments to the weights in the direction that minimizes loss.\\n* **Optimization Algorithms:** Algorithms used to update weights based on calculated gradients, such as stochastic gradient descent.\\n\\n\\n**Next Steps:**\\n\\n1. **Identify Appropriate Pre-trained Model:** Research pre-trained image recognition models and select one that aligns with the complexity of your task (e.g., MobileNetV2, ResNet).\\n2. **Acquire/Create Dataset:** Gather a sizable dataset of labeled images, ensuring good quality and adequate representation of dog variations.\\n3. **Implement Fine-tuning:** Write or adapt code in a suitable machine learning framework (TensorFlow, PyTorch) to implement the fine-tuning process (freezing, adjusting, training).\\n4. **Evaluation and Tuning:** Evaluate the model\\'s performance on a test set and adjust parameters (learning rate, batch size) to optimize accuracy and prevent overfitting.\\n5. **Iterative Process:** Fine-tuning often involves multiple iterations and refinements to achieve optimal results.  Experiment with different dataset sizes, pre-trained models, and hyperparameters to find the best setup.\\n6. **Explore Libraries/Tools:** Research the use of specialized tools/libraries for image classification and pre-trained models in the selected machine learning framework.\\n\\n\\nThis summary provides a structured overview.  Further research and experimentation will be needed to implement and adapt the fine-tuning process for your specific scenario.\\n', type='TextMessage')], stop_reason=\"'summary_agent' answered\")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}